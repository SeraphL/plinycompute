
\section{Experiments}

In this section, we describe our an experimental evaluation of the
performance of the PC distributed computation framework for a set of
representative big data analytics problems. The aim is to answer
following questions:

\begin {enumerate}
\item How useful is PC in building tools and libraries for big data analytics?
\item How efficient is PC in manipulating complex objects?
\item How well is PC in performing complex computations like real
  machine learning applications?
\end {enumerate}

\subsection {Experimental Environment and Applications}

All of the experiments reported in this paper were performed in a
cluster that consists of eleven Amazon EC2 m2.4xlarge machines,
running Ubuntu 16.04. Each machine had eight virtual cores, one SSD
disk, and 68 GB of RAM). One of the eleven machines serves as the Master
node and the rest ten machines serve as Worker nodes.

\vspace{5pt}
To conduct a convincing benchmarks and performance comparisons, we
select eight representative applications from three important categories
of big data analytics workloads:

\begin {itemize}
\item \texttt{Linear Algebra Library.} We constructed a linear algebra library
  and tested three common linear algebra computations: Gram Matrix,
  Linear Regression, and Nearest Neighbor Search.
\item \texttt{Analytical queries on TPC-H Data
    Set.}  We implemented two typical analytical queries against TPC-H
  benchmark data set, which contains complex nested objects: the first one is an aggregation query reporting which customer buys which
  parts for each supplier; the second one is a Top-K similarity query
  to search for K customers who buy the most similar items with a
  certain customer.
\item \texttt{Machine Learning.} We also implemented three widely used
  machine learning algorithms: \textbf{Latent Dirichlet Allocation (LDA)}--A
  generative statistic model for text topic mining;
  \textbf{Gaussian Mixture Model (GMM)}--A clustering algorithm to generate a composite
  distribution whereby points are drawn from one of multiple Gaussian distributions;  and \textbf{KMeans}-- A well-known clustering algorithm that clusters
  data points into a pre-defined number of clusters.
\end {itemize}

\subsection {Construction of a linear algebra library}
Since PC is designed to support the construction
of high-performance tools and libraries, our first benchmarking effort was aimed at determining 
whether PC is actually useful for that task.  Thus, we asked
a graduate student who knew nothing of PC to use the system to build a small Matlab-like 
programming language and library for distributed matrix operations.
We called this implementation \texttt{LilLinAlg}.
Our goal was to determine the 
performance and functionality that an expert programmer (but PC novice) could deliver in a short
timeframe, compared to a set of established distributed Big Data matrix implementations:
SciDB \cite{brown2010overview, stonebraker2011architecture} (built from the ground up by an MIT team over the last nine years), MLLib \cite{meng2016mllib} 
(the Big Data matrix
implementation shipped with Spark), and SystemML \cite{boehm2014hybrid, ghoting2011systemml, boehm2016systemml}
(a matrix and machine learning implementation developed
over the last seven years by a team at IBM, built on top of Spark and Hadoop).
The student spent about six weeks in this effort.

We ran three different computations:
a Gram matrix computation (given a matrix $\textbf{X}$, compute
$\textbf{X}^T \textbf{X}$), least squares linear regression (given a matrix of features $\textbf{X}$ and
responses $\textbf{y}$, compute 
$\hat{\pmb{\beta}} = (\textbf{X}^{T} \textbf{X})^{-1} \textbf{X}^{T} \textbf{y}$), and nearest
neighbor search in a Riemannian metric space \cite{lebanon2006metric} encoded by matrix $\textbf{A}$ (that is,
given a query vector
$\textbf{x}'$ and matrix $\textbf{X}$, find the $k$ rows in the matrix that minimize 
$d_{\textbf{A}}^2(\textbf{x}_i, \textbf{x}') = 
(\textbf{x}_i - \textbf{x}')^T\textbf{A}(\textbf{x}_i - \textbf{x}')$).  All experiments used
ten Amazon
EC2 m2.4xlarge machines.  For
all three computations, 
$10^6$ data points were used.  Results are given in 
Table \ref{fig:LR} (for Gram and regression, SystemML V0.9 on Hadoop was used; for
nearest neighbor, V1.0 on Spark was used).


\begin{table}[h!]
\begin{center}
\begin{tabular}{|c||c|c|c||c|c|c||c|c|c||}
\hline
& \multicolumn{3}{c||}{Gram Matrix} & \multicolumn{3}{c||}{Linear Regression} & \multicolumn{3}{c||}{Nearest Neighbor} \\
\hline
Dimensionality & $10$ & $10^2$ & $10^3$& $10$ & $10^2$ & $10^3$& $10$ & $10^2$ & $10^3$ \\
\hline
\hline
PC (\texttt{LilLinAlg}) &00:07 & 00:09 &00:39 &00:14 &00:22 &00:49& 00:15 & 00:20 & 01:06 \\
SystemML &00:05$*$ &00:51 &02:34 &00:06$*$ &00:53 &02:38 &00:04$*$ &00:30 &01:32 \\
Spark \texttt{mllib} &00:20  &00:54 &17:31 &00:35 &01:01 &17:42 &01:20 & 04:49 &14:30 \\
SciDB   &00:03 &00:17 &03:20 &00:15 &00:33 &06:04 &00:28 &02:56 & 06:24 \\
\hline
\end{tabular}
\caption{Linear algebra benchmark. Format is MM:SS.
A star ($*$) indicates running in local mode.}
\label{fig:LR}
\end{center}
\end{table}

In every case except for the small problems when SystemML chose not to distribute the data,
\texttt{LilLinAlg} was the fastest.  
Though SystemML nearest neighbor approached the speed of 
\texttt{LilLinAlg}, we point out the vast difference in engineering effort between the two systems.  
SystemML was built over many years by a team of PhDs. Research papers have been written about the
technology developed for the system, including one awarded a VLDB best paper award \cite{boehm2016systemml}.
\texttt{LilLinAlg} was developed in six weeks, and it is faster (though to be fair, SystemML has a much broader
set of capabilities than \texttt{LilLinAlg}).

\subsection{Big object-oriented data manipulation}
For an example of the raw performance of the PC object model and its ability to power large-scale 
object-oriented computations, we use the TPC-H benchmark data set \cite{council2008tpc}
and de-normalize
the data into a large set of \texttt{Customer} objects. Each
\texttt{Customer} object contains, among
other data, a list
or \texttt{Order} objects, and each \texttt{Order} object contains a list of \texttt{Lineitem} objects,
each of which has a \texttt{Part} and \texttt{Supplier} object.  
We run two computations. First, we compute, for each supplier,
the set of parts that the supplier has sold to each customer (stored
as a map from customer name to a list of part identifiers).
Second, we compute the $k$ customers whose set of \texttt{Part} items purchased is closest to
a query set, according to Jaccard similarity.
Because the data are object-oriented, it
is not possible to use Spark's Dataset/DataFrame abstraction to implement this computation, and so
we compare algorithmically equivalent Spark RDD and PC implementations.
Results are in Table \ref{fig:TPC}, run on the same 10 machine cluster.  

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c||c|c|c|c|c|c|}
\hline
Kryo data size: &41.5GB & 83.1GB & 167.2GB &251.1GB &333.2 &416.2GB \\
\hline
& \multicolumn{6}{c|}{\texttt{Customer}s per \texttt{Supplier}} \\
\hline
PlinyCompute: hot PDB & 00:11&	00:19&	00:35&	00:51&	01:08&	01:21 \\
Spark: hot HDFS & 01:04&	01:53&	03:24&	04:54&	06:25&	08:16\\
Spark: in-RAM RDD & 00:16& 	00:29& 	00:56& 	01:21& 	02:18& 	03:56\\
\hline
& \multicolumn{6}{c|}{top-$k$ Jaccard} \\
\hline
PlinyCompute: hot PDB & 00:03&	00:03&	00:04&	00:05&	00:05&	00:06 \\
Spark: hot HDFS & 00:56&	01:38&	03:01 & 04:01&	05:22&	06:34\\
Spark: in-RAM RDD & 00:08& 	00:12& 	00:21 & 00:32& 	01:11& 	02:38\\
\hline
\end{tabular}
\caption{PlinyCompute vs. Spark for large-scale OO computation. Times in MM:SS.}
\label{fig:TPC}
\end{center}
\end{table}

We see that in a somewhat fair comparison, when PC data are
stored in a hot Pliny Database (PDB for short; PDB is PC's backend storage system) and Spark data
are stored in
a hot HDFS, the computation is $6\times$ to $66\times$ faster in PC.  We say ``somewhat'' fair
because at the end of the computation, Spark is left with a large number of objects that still need to be 
garbage collected by the JVM---a cost not included in the computation. If the data are already
fully deserialized and stored as an RDD, PC is 
between 50\% and $26\times$ faster.  However, we point out that this is not an apples-to-apples comparison.
Among other costs, it ignores
the cost Spark would incur at a later time to free the objects stored in RAM.

\subsection {Machine Learning}
Finally, we describe our experience writing a word-based, non-collapsed LDA implementation \cite{jermaineExperimental} on top of
both Spark and PC.  LDA is a standard text mining algorithm and non-collapsed LDA is chosen because
it is challenging:
it contains two joins and two aggregations among other operations.
Our Spark combined RDD and DataSet        
implementation was carefully engineered by an expert.
On the cluster used before, we run LDA over a 2.5 million document database.  Results (per iteration) are:

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c||c|c|c|c|c|c|}
\hline
PlinyCompute & \makecell{Spark 1: \\vanilla} & \makecell{Spark 2: also with \\join hint} & \makecell{Spark 3: also with \\forced persist} & \makecell{Spark 3: also hand-\\coded multinomial} \\
\hline
02:05 & 50:20 & 17:30 & 09:26 & 05:00 \\
\hline
\end{tabular}
\caption{PlinyCompute vs. Spark for LDA. Times in MM:SS, averaged over five iterations.}
\label{fig:LDA}
\end{center}
\end{table}


While Spark performed well---in the end, PC was somewhat
limited by the lack of engineering that has gone
into its broadcast protocol---the 
amount of work required to arrive at a good solution 
was significant, representing about a week of tuning.  First, among other things, our Spark expert had to force a 
broadcast join.  Then, it was necessary to force Spark to
persist the result of one of the joins for later use.  Finally, it was necessary to hand-code a 
Multinomial sampler to obtain an implementation that was competitive with PC.
This illustrates the advantage of PC's declarative approach: decisions such as broadcast vs. full hash
join as well as which intermediate results to materialize are automated.  


