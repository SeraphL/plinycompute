
\section{Related Work}
\noindent
\textbf{Code Generation.} DryadLinq~\cite{yu2008dryadlinq} allows a user to express
distributed data flow
computations in a high-level language like C\# and strongly typed .NET
objects, and it compiles those computations into .NET assembler.
% Chris note: comparing with a relational system seems out of place
% Hyper~\cite{neumann2011efficiently} is a relational system,
% and it proposes a code
% generation strategy for query compilation to translate relational
% algebra to LLVM assembler for execution.  
LegoBase~\cite{klonatos2014building} switches the interface
from declarative SQL to a high-level language (Scala) and uses a query engine
written in Scala as a code generator to emit specialized and low-level
C code for execution. TupleWare~\cite{crotty2015tupleware} supports
multiple high-level languages (any language with an LLVM compiler) 
and aims to
optimize for UDFs by utilizing code
generation to integrate UDF code with the engine 
code. 
Weld~\cite{palkar2017weld} is a recent system developed in Scala and
Python. It proposes
a common runtime for data analytics libraries by asking library
developers to express their work using a new intermediate
representation (IR) and compiles this IR into multi-threaded code using
LLVM.  Then, application developers can use unified APIs to
call different libraries from Weld. Since version 2.0, Spark~\cite{zaharia2012resilient}
also exploits whole-stage code generation to generate JVM 
code.  The goal is mainly to reduce type parsing and virtual function call
overhead. PC uses a form of code generation (template metaprogramming) but 
the emphasis is quite different, in the sense that the goal is to allow for
efficient distributed programming with complex objects.

\vspace{5pt}
\noindent
\textbf{Optimized Memory Management.} 
Apache SparkSQL~\cite{armbrust2015spark} serializes 
relational tables into byte arrays and stores the serialized bytes
in a main-memory columnar storage. Spark Tungsten~\cite{tungsten}
optimizes the Spark execution backend by grouping execution
data (such as hashed aggregation data) 
into byte arrays and data can be allocated off-heap via
the sun.misc.Unsafe API, reducing
GC overhead. Deca~\cite{lu2016lifetime} is a memory management framework aiming at
reducing GC overhead. It stores
various Spark data types, e.g. UDF variables, user data and
shuffle data into different
off-heap containers so that objects in each container can have a similar
lifetime and can be recycled together.
All of these methods attempt to alleviate GC overhead; in contrast, PC simply does
not use a managed runtime.

\vspace{5pt}
\noindent
\textbf{Relational Processing on Binary or Structured Objects.} 
Apache Flink~\cite{alexandrov2014stratosphere} uses reflection
to analyze Java/Scala object types, and it
maps each object type to one of a limited set of
fundamental data types to provide comparators to efficiently compare binary
representations and extract fixed-length binary key prefixes without
deserializing the whole object.

Spark~\cite{tungsten} has introduced the Dataset/Dataframe 
to encode JVM objects into relational binary data representation. 
Datasets/Dataframes enable relational-style processing
through a relational query optimizer called Catalyst and
also enables Java intermediate code generation to reduce virtual
function call overhead through Tungsten~\cite{tungsten}. 

Such techniques significantly boost performance, by moving away from a flexible, object-oriented
type of system to a more relational system.
It is known that relational systems can be fast, but they limit the sort of applications that
can easily be coded on top of the system.  In contrast, PC attempts to offer a fully 
object-oriented interface.

\vspace{5pt}
\noindent
\textbf{Native Systems.} 
Impala~\cite{bittorf2015impala} is a
C++-based 
SQL query engine that relies on Hadoop for scalability and 
flexibility in interface and schema. Impala compiles SQL 
into LLVM assembler.
However,
Impala uses a relational data model (though it can read/write
semi-structured data in storage formats such as Arvo, Parquet, RC and so
on from/to external storage such HDFS, using standard
serialization/deserialization methods).

Google Spanner~\cite{bacon2017spanner} is a distributed
database system with a SQL query processor. It implements a
dialect of SQL, which uses arrays and structures to
support nested data as a first class citizen. To integrate
with user applications, the relational data described needs to
be translated to protocol buffers or user languages. PC takes a fundamentally different approach, as all code is 
object-oriented rather an a mix of SQL and other high (or medium) level languages.

Tensorflow~\cite{abadi2016tensorflow} is a
distributed computing framework mainly designed for deep learning. It
mainly supports processing of numerical data with a
very limited set of types.
Tensorflow provides
a much lower level API than PC's declarative interface, based on tensors,
variables and sessions.


