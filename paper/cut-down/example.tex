\section{$k$-means Example}
\label{sec:example}
Imagine that a user wished to use PC to build a high-performance
library implementation of a $k$-means algorithm \footnote{The $k$-means implementation
    described in this section is
    different with (and much simpler than) the implementation we used
    for benchmark in Section~\ref{sec:exp}.}.
Once the programmer had defined the basic type over which the clustering is to be performed (such as the
\texttt{DataPoint} class), 
a programmer would likely next define a simple class that allows the averaging of vectors:

\begin{codesmall}
class Avg : public Object {
	long cnt = 1;
	Handle <Vector <double>> data = nullptr;
	Avg &operator + (Avg &addMe)
           {/* add addMe into this */}
};
\end{codesmall}

\noindent
The programmer might next add a method to the \texttt{DataPoint} class that converts the \texttt{DataPoint} object to an \texttt{Avg} object:

\begin{codesmall}
Avg DataPoint :: fromMe () {
	Avg returnVal;
	returnVal.data = data;
	return returnVal;
}
\end{codesmall}

\noindent
And also add a method to the \texttt{DataPoint} class that accepts a set of centroids, computes the Euclidean distance to
each, and returns the closest:

\begin{codesmall}
long DataPoint :: getClose (Vector <Vector <double>> 
        &centroids) {...}
\end{codesmall}

\noindent
Next, a programmer using PC would define an \texttt{AggregateComp} class using PC's lambda calculus, since, after all, the $k$-means algorithm is essentially 
an aggregation:

\begin{codesmall}
class GetNewCentroids : public AggregateComp 
    <Centroid, long, Avg, DataPoint> {

public:
   Vector <Vector <double>> centroids;

   Lambda <long> getKeyProjection (
       Handle <DataPoint> aggMe) override {
          return makeLambda (aggMe, 
              [&] (Handle <DataPoint> &aggMe) 
                 {return aggMe->
                     getClose (centroids);});
   }
   Lambda <Avg> getValueProjection (
       Handle <DataPoint> aggMe) override {
          return makeLambdaFromMethod 
              (aggMe, fromMe);
   }
};
\end{codesmall}

\noindent 
The declaration \texttt{AggregateComp <Centroid, long, Avg, DataPoint>} means that this computation aggregates
\texttt{DataPoint} objects.  For each data point, it will extract a key of type \texttt{long}, a value of type \texttt{Avg}, which will be
aggregated into objects of type \texttt{Centroid}.  To process each data point, the aggregation will use the lambdas constructed by
\texttt{getKeyProjection} and \texttt{get ValueProjection}.  
In this case, for example,
\texttt{getKeyProjec tion} builds a lambda, which simply invokes the native C++ lambda given in the code---this
native C++ lambda returns the identity of the centroid closest to the data point.

To build a computation using this aggregation class, a programmer would need to specify the \texttt{Centroid} class (the result of this aggregation):

\begin{codesmall}
class Centroid : public Object {
	long centroidId; 
	Avg data;
public:
	long &getKey () {return centroidId;}
	Avg &getVal () {return data;}
};
\end{codesmall}

\noindent
And then build up a computation using these pieces:

\begin{codesmall}
Handle <Computation> myReader = 
    makeObject <ObjectReader <DataPoint>>
     ("myDB", "mySet");
Handle <Computation> myAgg = makeObject 
    <GetNewCentroids> ();
myAgg->centroids = ... // initialize the model
myAgg->setInput (myReader);
Handle <Computation> myWriter =  makeObject <Writer
     <Centroid>> ("myDB", "myOutSet");
    myWriter->setInput (myAgg);
pcClient.executeComputations (myWriter);
\end{codesmall}

\noindent After execution, the set of updated centroids would be stored in \texttt{myDB.mySet}.
Performing this computation in a loop, where the centroids are repeatedly updated until convergence, completes the implementation.

